{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development of Loan Predictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Performance Evaluation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see below confusion matrix of our prediction:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: left;\">\n",
    "      <th>Actual/Prediction</th>\n",
    "      <th>Good Loan [0]</th>\n",
    "      <th>Bad Loan [1]</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Good loan [0]</th>\n",
    "      <td>TN</td>\n",
    "      <td>FP</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Bad Loan [1]</th>\n",
    "      <td>FN</td>\n",
    "      <td>TP</td>\n",
    "    </tr>\n",
    "    </tbody>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what metric shall we use for our model? Consider this:\n",
    "\n",
    "- We want model to be able to detect most of (if not all) possibly defaulted loan as much. For example, if there would be 10 loan to be defaulted, our model would be reliable  if all of those loan is tagged as `Bad Loan`. The metric is **sensitivity** (or *True Positive Rate*): the ratio of positive instances that are correctly detected by the model,\n",
    "$$sensitivity/TPR=\\frac{TP}{FN + TP}$$\n",
    "         \n",
    "- In an extreme case, **TPR** can be inflated by a model that tag most of the loan as `Bad Loan`, resulting in a huge number of *False Positive* prediction: most of the `Good Loan` tagged as `Bad Loan`. Therefore, another metric to watch is **FPR** (or *False Positive Rate*): the ratio of negative instance that are incorrectly tagged as positive instance,\n",
    "$$FPR=\\frac{FP}{TN + FP}$$\n",
    "- TPR is the ability of the model to detect potential loss, which should be avoided. On the other side, FPR is the consequence of its high sensitivity to positive instance, in our cases, we would miss potential profit. We want to optimize trade-off between both metrics. They are commonly considered in **Receiver Operating Characteristic** (ROC): Comparation of *TPR* and *FPR*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **The Dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already prepared the similar dataset for exclusively for training and testing:\n",
    "\n",
    "- Dataset for training: Loan Dataset of 2010 - 2015\n",
    "- Dataset for testing: Loan Dataset of 2016 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float', '{:.2f}'.format)\n",
    "pd.set_option('display.max_columns', 75)\n",
    "pd.set_option('display.max_rows', 75)\n",
    "\n",
    "train_set = pd.read_csv('dataset\\lc_2010-2015.csv', dtype={'desc': 'str', 'verification_status_joint': 'str'})\n",
    "test_set = pd.read_csv('dataset\\lc_2016-2017.csv', dtype={'desc': 'str', 'verification_status_joint': 'str'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparing the Dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part of dataset preparation, we will create a pipeline to transform the dataset which consists of:\n",
    "\n",
    "- Filtering the dataset: 1) To consider only `INDIVIDUAL` loan; 2) To exclude the on-going loan\n",
    "- Replacing missing values, as explained in previous section.\n",
    "\n",
    "I already developed classes for each of the activity: 1) `LoanDataLabelPredictor` for filtering; 2) `LoanDataMissingHandler` to handle missing data. The output of the pipeline is splitted predictor-label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 {color: black;background-color: white;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 pre{padding: 0;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-toggleable {background-color: white;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-item {z-index: 1;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-parallel-item:only-child::after {width: 0;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-2baed27d-cddb-4fe6-9ffc-25b4aa5ab0f5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;, LoanDataPreprocess()),\n",
       "                (&#x27;extract_label_predictor&#x27;,\n",
       "                 LoanDataLabelPredictor(exclude=[&#x27;loan_amnt&#x27;, &#x27;term&#x27;,\n",
       "                                                 &#x27;earliest_cr_line&#x27;])),\n",
       "                (&#x27;missing_handler&#x27;, LoanDataMissingHandler())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ad7e1591-6b4b-4d34-b4ed-17b5ccf0f1bb\" type=\"checkbox\" ><label for=\"ad7e1591-6b4b-4d34-b4ed-17b5ccf0f1bb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;, LoanDataPreprocess()),\n",
       "                (&#x27;extract_label_predictor&#x27;,\n",
       "                 LoanDataLabelPredictor(exclude=[&#x27;loan_amnt&#x27;, &#x27;term&#x27;,\n",
       "                                                 &#x27;earliest_cr_line&#x27;])),\n",
       "                (&#x27;missing_handler&#x27;, LoanDataMissingHandler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7a3dcdd3-1198-4da6-81b6-54cc7e40c225\" type=\"checkbox\" ><label for=\"7a3dcdd3-1198-4da6-81b6-54cc7e40c225\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LoanDataPreprocess</label><div class=\"sk-toggleable__content\"><pre>LoanDataPreprocess()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"110cd348-62a8-4417-8805-aa329e6bbb1c\" type=\"checkbox\" ><label for=\"110cd348-62a8-4417-8805-aa329e6bbb1c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LoanDataLabelPredictor</label><div class=\"sk-toggleable__content\"><pre>LoanDataLabelPredictor(exclude=[&#x27;loan_amnt&#x27;, &#x27;term&#x27;, &#x27;earliest_cr_line&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"83d9e7ad-8aac-44f0-8bca-02d1199fae6c\" type=\"checkbox\" ><label for=\"83d9e7ad-8aac-44f0-8bca-02d1199fae6c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LoanDataMissingHandler</label><div class=\"sk-toggleable__content\"><pre>LoanDataMissingHandler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess', LoanDataPreprocess()),\n",
       "                ('extract_label_predictor',\n",
       "                 LoanDataLabelPredictor(exclude=['loan_amnt', 'term',\n",
       "                                                 'earliest_cr_line'])),\n",
       "                ('missing_handler', LoanDataMissingHandler())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from modules.data_preprocess import LoanDataPreprocess, LoanDataMissingHandler, LoanDataLabelPredictor \n",
    "from sklearn import set_config\n",
    "\n",
    "dataset_preprocess = Pipeline([\n",
    "    ('preprocess', LoanDataPreprocess()),\n",
    "    ('extract_label_predictor', LoanDataLabelPredictor(exclude=['loan_amnt', 'term', 'earliest_cr_line'])),\n",
    "    ('missing_handler', LoanDataMissingHandler())\n",
    "    ])\n",
    "\n",
    "set_config(display='diagram')\n",
    "dataset_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nans Count</th>\n",
       "      <th>Nans Percentage (%)</th>\n",
       "      <th>Data Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>9132</td>\n",
       "      <td>4.34</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_12m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_24m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bal_il</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il_util</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_rv_12m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_rv_24m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_util</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_fi</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_cu_tl</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_12m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bal_bc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pymnt_plan</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Nans Count  Nans Percentage (%) Data Types\n",
       "emp_length                         9132                 4.34   category\n",
       "home_ownership                        0                 0.00   category\n",
       "annual_inc                            0                 0.00    float64\n",
       "verification_status                   0                 0.00   category\n",
       "dti                                   0                 0.00    float64\n",
       "delinq_2yrs                           0                 0.00    float64\n",
       "inq_last_6mths                        0                 0.00    float64\n",
       "mths_since_last_delinq                0                 0.00    float64\n",
       "mths_since_last_record                0                 0.00    float64\n",
       "open_acc                              0                 0.00    float64\n",
       "revol_bal                             0                 0.00    float64\n",
       "revol_util                            0                 0.00    float64\n",
       "total_acc                             0                 0.00    float64\n",
       "collections_12_mths_ex_med            0                 0.00    float64\n",
       "mths_since_last_major_derog           0                 0.00    float64\n",
       "policy_code                           0                 0.00    float64\n",
       "acc_now_delinq                        0                 0.00    float64\n",
       "tot_coll_amt                          0                 0.00    float64\n",
       "tot_cur_bal                           0                 0.00    float64\n",
       "open_acc_6m                           0                 0.00    float64\n",
       "open_il_12m                           0                 0.00    float64\n",
       "open_il_24m                           0                 0.00    float64\n",
       "mths_since_rcnt_il                    0                 0.00    float64\n",
       "total_bal_il                          0                 0.00    float64\n",
       "il_util                               0                 0.00    float64\n",
       "open_rv_12m                           0                 0.00    float64\n",
       "open_rv_24m                           0                 0.00    float64\n",
       "all_util                              0                 0.00    float64\n",
       "total_rev_hi_lim                      0                 0.00    float64\n",
       "inq_fi                                0                 0.00    float64\n",
       "total_cu_tl                           0                 0.00    float64\n",
       "inq_last_12m                          0                 0.00    float64\n",
       "pub_rec                               0                 0.00    float64\n",
       "max_bal_bc                            0                 0.00    float64\n",
       "int_rate                              0                 0.00    float64\n",
       "installment                           0                 0.00    float64\n",
       "grade                                 0                 0.00   category\n",
       "sub_grade                             0                 0.00   category\n",
       "pymnt_plan                            0                 0.00   category"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.data_exploration import DataExploration\n",
    "\n",
    "X_train, y_train = dataset_preprocess.fit_transform(train_set)\n",
    "DataExploration(X_train).show_nans_or_zeroes('nans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = dataset_preprocess.transform(test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous confusion matrix, we will map the label as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_array(x):\n",
    "    if x == 'Good Loan':\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "y_train = np.vectorize(map_array)(y_train)\n",
    "y_test = np.vectorize(map_array)(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Numerical Features**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our base model, let's first just consider scaling the features. This is commonly a standard practice and may turns out to give a good result. However, scaling is not necessary for `logistic regression` and tree-based method.\n",
    "\n",
    "For dataset which has outliers, scikit-learn provides scaling that robust to this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "robust_scaler = RobustScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Combining Feature Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include='category').columns.values\n",
    "numerical_cols = X_train.select_dtypes(exclude='category').columns.values\n",
    "ct = ColumnTransformer([\n",
    "    ('categorical', one_hot, categorical_cols),\n",
    "    ('numerical', robust_scaler, numerical_cols)\n",
    "    ])\n",
    "ct.fit(X_train)\n",
    "X_train_transfd = ct.transform(X_train)\n",
    "X_test_transfd = ct.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# creating model function, specify parameters to be cv-ed later\n",
    "def mlp_model(input_shape, n_hidden=5, n_neurons=100, learning_rate=3e-3, activation='relu'):\n",
    "    input_ = keras.layers.Input(shape=[input_shape,])\n",
    "    dense = keras.layers.Dense(n_neurons, activation=activation)(input_)\n",
    "    for layer in range(n_hidden - 1):\n",
    "        dense = keras.layers.Dense(n_neurons, activation=activation)(dense)\n",
    "    output_ = keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    model = keras.Model(inputs=[input_], outputs=[output_])\n",
    "    # compiling model\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# scoring\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "sssplit = StratifiedShuffleSplit(n_splits=10)\n",
    "# create a random forest classifier\n",
    "log_clf  = Pipeline([\n",
    "    ('feature_selection', RFECV(LogisticRegression(max_iter=1000), scoring=roc_auc_score)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "rf_clf  = Pipeline([\n",
    "    ('feature_selection', RFECV(RandomForestClassifier(), scoring=roc_auc_score)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "sv_clf  = Pipeline([\n",
    "    ('feature_selection', RFECV(SVC(), scoring=roc_auc_score)),\n",
    "    ('classifier', SVC())\n",
    "    ])\n",
    "mlp_clf  = \n",
    "# initialize an empty list to store the scores\n",
    "models = [log_clf, rf_clf, sv_clf, mlp_clf]\n",
    "model_ids = ['logisticreg', 'random forest', 'svm', 'mlp']\n",
    "# iterate over the models\n",
    "for model, model_id in zip(models, model_ids):\n",
    "    model_scores = []\n",
    "    # iterate over the splits\n",
    "    for train_index, valid_index in sssplit.split(X_train_transfd):\n",
    "        # get the training and validation data for this split\n",
    "        X_train_s, X_valid_s = X_train_transfd.iloc[train_index, :], X_train_transfd.iloc[valid_index, :]\n",
    "        y_train_s, y_valid_s = y_train[train_index], y_train[valid_index]\n",
    "        # fit the model to the training data\n",
    "        model.fit(X_train_s, y_train_s)\n",
    "        # use the model to make predictions on the validation data\n",
    "        y_pred_s = model.predict(X_valid_s)\n",
    "        # calculate the accuracy score for this split\n",
    "        score = roc_auc_score(y_valid_s, y_pred_s)\n",
    "        model_scores.append(score)\n",
    "    # calculate the mean and standard deviation of the scores\n",
    "    # this is model-specific\n",
    "    mean_score = np.mean(model_scores)\n",
    "    std_dev_score = np.std(model_scores)\n",
    "    # print the mean and standard deviation of the scores\n",
    "    print(f'{model_id}: Mean score = {mean_score:.2f}, Standard deviation = {std_dev_score:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to select several potentially baseline model for our classification task!\n",
    "For each potential model, we are going to observe how the model performs by comparing the model performance. And also, we will perform *Feature Selection* using `Recursive Feature Elimination (RFE)`, focusing on `accuracy` score of `Charged Off` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Stochastic Gradient Descent Classifier (SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features_evaluator = RFECV(estimator=sgd_clf, cv=StratifiedKFold(2), scoring='recall')\n",
    "features_evaluator.fit(X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}))\n",
    "rfecv_mean = features_evaluator.cv_results_['mean_test_score']\n",
    "optimal_n_features = features_evaluator.n_features_\n",
    "\n",
    "# plotting\n",
    "def plot_feature_evaluator(rfecv_mean, optimal_n_features):\n",
    "    plt.plot(\n",
    "        range(1, len(rfecv_mean) + 1), rfecv_mean\n",
    "    )\n",
    "    plt.xlabel('Number of features selected')\n",
    "    plt.ylabel('Cross validation score')\n",
    "    print(f'Optimal number of features: {optimal_n_features}')\n",
    "\n",
    "plot_feature_evaluator(rfecv_mean, optimal_n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selector = RFECV(\n",
    "    estimator=sgd_clf, cv=StratifiedKFold(2), scoring='recall',\n",
    "    min_features_to_select=optimal_n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "sgd_clf_model = Pipeline([\n",
    "    ('features_selector', features_selector),\n",
    "    ('sgd_classifier', SGDClassifier(random_state=99))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Performance Measure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# decision function to plot precision-recall curve\n",
    "y_train_pred = \\\n",
    "    cross_val_predict(\n",
    "        sgd_clf_model, X_train_res_transf, \n",
    "        y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), cv=3)\n",
    "confusion_matrix(y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.lineplot(x=thresholds, y=precisions[:-1], ax=ax, label='Precision')\n",
    "    sns.lineplot(x=thresholds, y=recalls[:-1], ax = ax, label='Recall')\n",
    "    ax.lines[0].set_linestyle('--')\n",
    "    ax.lines[1].set_linestyle('-')\n",
    "    plt.xlabel('Treshold')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    # plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "y_scores_sgd = \\\n",
    "    cross_val_predict(\n",
    "        sgd_clf_model, X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), cv=3,\n",
    "        method='decision_function')\n",
    "precisions, recalls, thresholds = \\\n",
    "    precision_recall_curve(y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), y_scores_sgd)\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recalls(precisions, recalls):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.lineplot(x=precisions, y=recalls, ax=ax)\n",
    "    plt.xlabel('Precisions')\n",
    "    plt.ylabel('Recalls')\n",
    "    \n",
    "plot_precision_recalls(precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), y_scores_sgd)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (recall)')\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}), y_scores_sgd)\n",
    "\n",
    "print(f'AUC Score= {auc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "sgd_clf_model.fit(X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}))\n",
    "y_pred_test = sgd_clf_model.predict(X_test_transf)\n",
    "\n",
    "print(classification_report_imbalanced(y_test.map({'Fully Paid': 0, 'Charged Off': 1}), y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(verbosity=0, use_label_encoder=False)\n",
    "xgb_clf.fit(X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}))\n",
    "y_pred_test = xgb_clf.predict(X_test_transf)\n",
    "\n",
    "print(classification_report_imbalanced(y_test.map({'Fully Paid': 0, 'Charged Off': 1}), y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_evaluator = RFECV(estimator=xgb_clf, cv=StratifiedKFold(2), scoring='recall')\n",
    "features_evaluator.fit(X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}))\n",
    "rfecv_mean = features_evaluator.cv_results_['mean_test_score']\n",
    "optimal_n_features = features_evaluator.n_features_\n",
    "\n",
    "plot_feature_evaluator(rfecv_mean, optimal_n_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selector = RFECV(\n",
    "    estimator=xgb_clf, cv=StratifiedKFold(2), scoring='recall',\n",
    "    min_features_to_select=optimal_n_features)\n",
    "\n",
    "xgb_clf_model = Pipeline([\n",
    "    ('features_selector', features_selector),\n",
    "    ('xgb_classifier', XGBClassifier(verbosity=0))\n",
    "])\n",
    "\n",
    "xgb_clf_model.fit(X_train_res_transf, y_train_res.map({'Fully Paid': 0, 'Charged Off': 1}))\n",
    "y_pred_test = xgb_clf.predict(X_test_transf)\n",
    "\n",
    "print(classification_report_imbalanced(y_test.map({'Fully Paid': 0, 'Charged Off': 1}), y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2892b95998397e64822f38de2e41a1410cc5bda2d9d70e92f4ade4b6aa0470a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
